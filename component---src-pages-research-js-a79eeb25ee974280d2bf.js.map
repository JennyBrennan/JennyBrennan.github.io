{"version":3,"file":"component---src-pages-research-js-a79eeb25ee974280d2bf.js","mappings":"wLAIMA,EAAAA,SAAAA,GAAAA,SAAAA,IAAAA,OAAAA,EAAAA,MAAAA,KAAAA,YAAAA,KAgCD,OAhCCA,EAAAA,EAAAA,GAAAA,EAAAA,GAAAA,EAAAA,UACFC,OAAA,WACI,OACI,gBAAC,IAAD,KACI,gBAAC,IAAD,CAAUC,MAAM,4BAA4BC,KAAK,mCAAmCC,UAAU,sCAC9F,+BACI,sCACA,4JACA,oLACA,sBAAIC,GAAG,uBAAP,uBACA,0BACI,0BAAI,qBAAGC,KAAK,oCAAR,wEAAJ,sQACA,0BAAI,qBAAGA,KAAK,oCAAR,mFAAJ,+DACA,0BAAI,qBAAGA,KAAK,oGAAR,6DAAJ,kCACA,0BAAI,qBAAGA,KAAK,wFAAR,sEAAJ,kCACA,0BAAI,qBAAGA,KAAK,yFAAR,2GAAJ,0EACA,0BAAI,qBAAGA,KAAK,8GAAR,mDAAJ,4CACA,0BAAI,qBAAGA,KAAK,yGAAR,oEAAJ,kCACA,0BAAI,qBAAGA,KAAK,6GAAR,wEAAJ,mCAEJ,sBAAID,GAAG,qBAAP,uBACA,0BACI,0BAAI,qBAAGC,KAAK,mHAAR,+DAAJ,oCACA,0BAAI,qBAAGA,KAAK,iHAAR,8EAAJ,8BACA,0BAAI,qBAAGA,KAAK,iFAAR,sCAAJ,0GACA,0BAAI,qBAAGA,KAAK,gHAAR,mFAAJ,yCACA,0BAAI,qBAAGA,KAAK,2FAAR,0CAAJ,6EACA,0BAAI,qBAAGA,KAAK,iGAAR,4DAAJ,6CAKnB,EAhCCN,CAAqBO,EAAAA,WAmC3B","sources":["webpack://jennybrennan.github.io/./src/pages/research.js"],"sourcesContent":["import React from \"react\"\nimport Layout from \"../components/layout\"\nimport Metadata from \"../components/metadata\"\n\nclass ResearchPage extends React.Component {\n    render() {\n        return (\n            <Layout>\n                <Metadata title=\"Research by Jenny Brennan\" desc=\"On data, AI, policy and society.\" canonical=\"https://jennybrennan.com/research\"/>\n                <article>\n                    <h1>Research</h1>\n                    <p>My current focus area is methods, governance mechanisms, policy, infrastructure and capacity building for evaluating AI models.</p>\n                    <p>My previous research has included developing algorithmic impact assessments, as well as transparency and accountability for of AI in the public sector.</p>\n                    <h2 id=\"recent-publications\">Recent publications</h2>\n                    <ul>\n                        <li><a href=\"https://arxiv.org/abs/2404.14068\">Holistic Safety and Responsibility Evaluations of Advanced AI Models</a>, 2024, Weidinger, L., Barnhart, J., Brennan, J., Butterfield, C., Young, S., Hawkins, W., Hendricks, L.A., Comanescu, R., Chang, O., Rodriguez, M., Beroshi, J., Bloxwich, D., Proleev, L., Chen, J., Farquhar, S., Ho, L., Gabriel, I., Dafoe, A. and Isaac, W. </li>\n                        <li><a href=\"https://arxiv.org/abs/2306.09871\">Going public: the role of public participation approaches in commercial AI labs</a>, 2023, Groves, L., Peppin, A., Strait, A., and Brennan, J.</li>\n                        <li><a href=\"https://www.adalovelaceinstitute.org/report/algorithmic-impact-assessment-case-study-healthcare/\">Algorithmic impact assessment: a case study in healthcare</a>, 2022, Ada Lovelace Institute</li>\n                        <li><a href=\"https://www.adalovelaceinstitute.org/report/technical-methods-regulatory-inspection/\">Technical methods for regulatory inspection of algorithmic systems</a>, 2021, Ada Lovelace Institute</li>\n                        <li><a href=\"https://www.adalovelaceinstitute.org/report/algorithmic-accountability-public-sector/\">Algorithmic accountability for the public sector: Learning from the first wave of policy implementation</a>, 2021, Ada Lovelace Institute, AI Now and Open Government Partnership</li>\n                        <li><a href=\"https://www.adalovelaceinstitute.org/algorithms-in-social-media-realistic-routes-to-regulatory-inspection/\">Inspecting algorithms in social media platforms</a>, 2021, Ada Lovelace Institute and Reset</li>\n                        <li><a href=\"https://www.adalovelaceinstitute.org/examining-the-black-box-tools-for-assessing-algorithmic-systems/\">Examining the black box: tools for assessing algorithmic systems</a>, 2020, Ada Lovelace Institute</li>\n                        <li><a href=\"https://www.adalovelaceinstitute.org/beyond-face-value-public-attitudes-to-facial-recognition-technology/\">Beyond face value: public attitudes to facial recognition technology</a>, 2019, Ada Lovelace Institute</li>\n                    </ul>\n                    <h2 id=\"press-media-blogs\">Press, media, blogs</h2>\n                    <ul>\n                        <li><a href=\"https://www.newstatesman.com/spotlight/cyber/2021/12/why-ofcom-needs-clear-powers-to-audit-big-techs-algorithms\">Why Ofcom needs clear powers to audit Big Tech's algorithms</a> - written for The New Statesman</li>\n                        <li><a href=\"https://venturebeat.com/2021/12/08/the-u-k-s-new-ai-transparency-standard-is-a-step-closer-to-accountable-ai/\">The U.K.'s new AI transparency standard is a step closer to accountable AI</a> - written for VentureBeat</li>\n                        <li><a href=\"https://www.adalovelaceinstitute.org/blog/getting-under-the-hood-of-big-tech/\">Getting under the hood of Big Tech</a> - on auditing in the EU Digital Services Act with Alex Circuimaru for the Ada Lovelace Institute blog</li>\n                        <li><a href=\"https://www.adalovelaceinstitute.org/blog/algorithms-social-media-realistic-routes-to-regulatory-inspection/\">Algorithms in social media platforms: realistic routes to regulatory inspection</a> - on the Ada Lovelace Institute blog</li>\n                        <li><a href=\"https://charitydigital.org.uk/topics/topics/understanding-the-impact-of-algorithms-7472\">Understanding the impact of algorithms</a> - co-authored with DataKind UK CEO Giselle Cory for Charity Digital News</li>\n                        <li><a href=\"https://www.adalovelaceinstitute.org/facial-recognition-defining-terms-to-clarify-challenges/\">Facial recognition: defining terms to clarify challenges</a> - on the Ada Lovelace Institute blog</li>\n                    </ul>\n                </article>\n            </Layout>\n        )   \n    }\n}\n\nexport default ResearchPage"],"names":["ResearchPage","render","title","desc","canonical","id","href","React"],"sourceRoot":""}